#!/bin/bash
# setup to use the virtualenv
source venv/bin/activate


# Make sure that necessary executables are installed
for b in yarn virtualenv pip jq aws
do
    command -v $b >/dev/null 2>&1 || { echo >&2 "I require $b but it's not installed.  Aborting."; exit 1; }
done


# Set allexport mode, all variables defined in this block will get exported
set -a
# Name of the stack being created
: ${HLS_STACKNAME:=hls}



#### LAADS configurations ###
# Bucket name for Laads Data
HLS_LAADS_BUCKET=${HLS_STACKNAME}-bucket

#Token for accessing Laads data, you can get from https://ladsweb.modaps.eosdis.nasa.gov/tools-and-services/data-download-scripts/#appkeys
# HLS_LAADS_TOKEN=
[[ ! -v HLS_LAADS_TOKEN ]] && echo "HLS_LAADS_TOKEN must be set" && exit 1

# Schedule to use for updating Laads data
HLS_LAADS_CRON="cron(0 0/12 * * ? *)"

# Bucket that can be used to bootstrap EFS mount with existing Laads data in S3 using s3 sync
HLS_LAADS_BUCKET_BOOTSTRAP=${HLS_LAADS_BUCKET}



### Sentinel Processing Configurations ###
# ECR Url for hls-sentinel docker image
HLS_SENTINEL_ECR_URI="018923174646.dkr.ecr.us-west-2.amazonaws.com/hls-sentinel:latest"

# Bucket used to 
HLS_SENTINEL_BUCKET=${HLS_STACKNAME}-sentinel-output


# end of allexport mode
set +a

# Set environment variables for all outputs set up in cloud formation
stack_info=$(aws cloudformation describe-stacks --stack-name ${HLS_STACKNAME} --output json)
if [[ "$stack_info" =~ "OutputKey" ]]; then
    l=$(echo "$stack_info" | jq ".Stacks[].Outputs | length")
    for ((i=0;i<$l;++i)); do
        key=$(echo "$stack_info" | jq ".Stacks[].Outputs[$i].OutputKey" | sed -e 's/^"//'  -e 's/"$//')
        key=${key::-8}
        key=${key^^}
        val=$(echo "$stack_info" | jq ".Stacks[].Outputs[$i].OutputValue" | sed -e 's/^"//'  -e 's/"$//')
        export "HLSSTACK_$key"="$val"
    done
fi